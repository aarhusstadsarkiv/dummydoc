import argparse
import sqlite3
import tiffprinter

from sqlite3.dbapi2 import Connection
from typing import List


def dummydoc(file: str) -> None:
    """
    * Takes a path to a database generated by Digiarch

    * Prints a list of every dummy tiff file entry in the database
    """
    # Define checksums to look for, put them in a list.
    # We're using a list of lists 'cus we need to check for both
    # the new, compressed templates and the old, uncompressed ones
    # JUST to be safe!
    dummyChecksumCollection: List[List[str]] = [[] for _ in range(5)]

    # "corrupted file" checksums
    dummyChecksumCollection[0].append(
        "50a33547e3d47c5dba7282c9e7fd72f96415190131b6326ed72327dc1f966c23"
    )
    dummyChecksumCollection[0].append(
        "0e1d4f99448afb96883a8ddc2013ed118b50bd13867c40d76366fe51741a4879"
    )
    # "empty file" checksums
    dummyChecksumCollection[1].append(
        "86b54cf579de41c77966110c6ea2cebcb463497741c0852c3a2fa0eb6147c6bb"
    )
    dummyChecksumCollection[1].append(
        "cc35f2524ed5d5241b76cf0ffade8fd9b6ae7ec1e2178572ad3fdeadbb6b7c29"
    )
    # "no known software" checksums
    dummyChecksumCollection[2].append(
        "7505e62d0e47b61298916e49c394a013a2119527738cc072ad3eb2ae6407a913"
    )
    dummyChecksumCollection[2].append(
        "08992a01890a2a58c45cf0d547a93c49ab55e2c2ea92da6e978b5204aa9b6e26"
    )
    # "not preservable" checksums
    dummyChecksumCollection[3].append(
        "180dddb2b4563c84caf9fb8eee919c22388b62d86b875613ecb88423b2a0b696"
    )
    dummyChecksumCollection[3].append(
        "58d6193d4f1456d92b74b4cfb77bea63b8a43669fab8e848c434b400e519898d"
    )
    # "password protected" checksums
    dummyChecksumCollection[4].append(
        "1f02c224c2acc2110a8c04cf1232402ad18bf7a1c5404140dfd6cc1f0f61b764"
    )
    dummyChecksumCollection[4].append(
        "a4c8b06ec798f8cf98fc39935587af060496cfccb01fd8a626d7a3b731264601"
    )

    # Create lists for each dummy tiff to house the dummy files we find
    # Pack them in a list?
    dummyLists: List[List[str]] = []
    for i in dummyChecksumCollection:
        dummyLists.append([])
    # This way the structure of the program is extensible and flexible
    # - if the dummy files change or new ones are added, the only thing
    # needed is to update the saved checksums
    # To make it even easier, we COULD actually calculate the checksums,
    # and have a folder with the dummy tiffs - then updating the program
    # would just mean modifying this folder!

    # "Connect" to the .db file
    try:
        con: Connection = sqlite3.connect(
            "file:" + file + "?mode=ro", uri=True
        )
        # Now, query the .db file, and look thru the result
        for path, checksum in con.execute(
            "SELECT aars_path, checksum FROM Files"
        ):
            for idx, dummyChecksums in enumerate(dummyChecksumCollection):
                if checksum in dummyChecksums:
                    dummyLists[idx].append(path)

    # if the path isn't pointing to a valid database file
    except sqlite3.DatabaseError:
        print(
            "Error: "
            + file
            + " isn't a path to a valid Digiarch-produced database!"
        )
        return

    # Create a .tif file documenting the dummy .tifs found
    tiffprinter.stringToTiffPrinter(
        unpackDummyLists(dummyLists), file[0:-8] + "dummytiffs.tiff"
    )


# simple helper function that "unpacks" the multiple
# dummy lists and converts it into a string
# it also adds very simple "headers"
def unpackDummyLists(dummyLists: List[List[str]]) -> str:
    unpackedList: str = ""
    # ignoring flake8 linelength check for the next 4 lines
    unpackedList += (
        "Dette er en oversigt over erstatningsdokumenter for digitale filer, som af følgende årsager ikke\n"  # noqa E501
        + "er blevet konverteret korrekt af Aarhus Stadsarkiv under produktionen af denne arkiveringsverion.\n"  # noqa E501
        + "Der er filer som ikke er bevaringsværdige, men som ikke blev sorteret fra af leverandøren før\n"  # noqa E501
        + "dataudtrækket blev leveret til Aarhus Stadsarkiv. Der er også filer som oprindeligt enten har\n"  # noqa E501
        + "været tomme eller korrumperede og derfor ikke er mulige at reparere, samt kodeordsbeskyttede\n"  # noqa E501
        + "filer som det ikke har været muligt at bryde koden på og trække ud fra det oprindelige system.\n"  # noqa E501
        + "Derudover er der filer, hvor der ikke kunne findes en softwareløsning som kunne konvertere dem\n"  # noqa E501
        + "til et bevaringsværdigt format.\n\n"  # noqa E501
    )

    headerList = [
        "korrumperede filer",
        "tomme filer",
        "filer uden en konverteringsløsning",
        "ikkebevaringsværdige filer",
        "kodeordsbeskyttede filer",
    ]
    for index, ls in enumerate(dummyLists):
        # only add header if there are files to go under it
        if len(ls) > 0:
            unpackedList += (
                "Antallet af erstatningsdokumenter for "
                + headerList[index]
                + " er "
                + str(len(ls))
                + " på følgende placeringer:\n"
            )

            for s in ls:
                unpackedList += "        " + s + "\n"
            unpackedList += "\n"

    return unpackedList[:-2]  # ignoring the newline right at the end


# Set up argparse stuff
# Not sure if this is where it should go

parser = argparse.ArgumentParser()
parser.add_argument(
    "file",
    help="the path to the database generated by Digiarch that's "
    + "to be searched for dummy tiff files",
    type=str,
)
args: argparse.Namespace = parser.parse_args()
dummydoc(args.file)
